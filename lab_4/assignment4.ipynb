{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2RQRgcfmdes"
      },
      "source": [
        "# Лабораторная работа 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RXrbBbNmdev"
      },
      "source": [
        "Tensorflow 2.x\n",
        "\n",
        "1) Подготовка данных\n",
        "\n",
        "2) Использование Keras Model API\n",
        "\n",
        "3) Использование Keras Sequential + Functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUPFB3ZKmdew"
      },
      "source": [
        "https://www.tensorflow.org/tutorials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-KLJDFXmdew"
      },
      "source": [
        "Для выполнения лабораторной работы необходимо установить tensorflow версии 2.0 или выше .\n",
        "\n",
        "Рекомендуется использовать возможности Colab'а по обучению моделей на GPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-21T10:32:01.394648Z",
          "start_time": "2024-03-21T10:32:01.378584Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TSC3kHzmdex",
        "outputId": "578f857b-cd13-40b4-fd67-6becc266d599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "USE_GPU = True\n",
        "\n",
        "if USE_GPU:\n",
        "    device = '/device:GPU:0'\n",
        "else:\n",
        "    device = '/cpu:0'\n",
        "\n",
        "# Constant to control how often we print when training models.\n",
        "print_every = 100\n",
        "print('Using device: ', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW9-fCBumdey"
      },
      "source": [
        "# Подготовка данных\n",
        "Загрузите набор данных из предыдущей лабораторной работы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-21T10:32:03.359832Z",
          "start_time": "2024-03-21T10:32:01.709774Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLLN4mzDmdez",
        "outputId": "03032cc7-cfb9-49a1-858e-483c07991c7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n",
            "Train data shape:  (49000, 32, 32, 3)\n",
            "Train labels shape:  (49000,) int32\n",
            "Validation data shape:  (1000, 32, 32, 3)\n",
            "Validation labels shape:  (1000,)\n",
            "Test data shape:  (10000, 32, 32, 3)\n",
            "Test labels shape:  (10000,)\n"
          ]
        }
      ],
      "source": [
        "def load_cifar10(num_training=49000, num_validation=1000, num_test=10000):\n",
        "    \"\"\"\n",
        "    Fetch the CIFAR-10 dataset from the web and perform preprocessing to prepare\n",
        "    it for the two-layer neural net classifier. These are the same steps as\n",
        "    we used for the SVM, but condensed to a single function.\n",
        "    \"\"\"\n",
        "    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n",
        "    cifar10 = tf.keras.datasets.cifar10.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10\n",
        "    X_train = np.asarray(X_train, dtype=np.float32)\n",
        "    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
        "    X_test = np.asarray(X_test, dtype=np.float32)\n",
        "    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
        "\n",
        "    # Subsample the data\n",
        "    mask = range(num_training, num_training + num_validation)\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[mask]\n",
        "    mask = range(num_training)\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    mask = range(num_test)\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "\n",
        "    # Normalize the data: subtract the mean pixel and divide by std\n",
        "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
        "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
        "    X_train = (X_train - mean_pixel) / std_pixel\n",
        "    X_val = (X_val - mean_pixel) / std_pixel\n",
        "    X_test = (X_test - mean_pixel) / std_pixel\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "# If there are errors with SSL downloading involving self-signed certificates,\n",
        "# it may be that your Python version was recently installed on the current machine.\n",
        "# See: https://github.com/tensorflow/tensorflow/issues/10779\n",
        "# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n",
        "#   ...replacing paths as necessary.\n",
        "\n",
        "# Invoke the above function to get our data.\n",
        "NHW = (0, 1, 2)\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10()\n",
        "print('Train data shape: ', X_train.shape)\n",
        "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
        "print('Validation data shape: ', X_val.shape)\n",
        "print('Validation labels shape: ', y_val.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-21T10:32:03.390892Z",
          "start_time": "2024-03-21T10:32:03.361829Z"
        },
        "id": "zFdFh2Tsmdez"
      },
      "outputs": [],
      "source": [
        "class Dataset(object):\n",
        "    def __init__(self, X, y, batch_size, shuffle=False):\n",
        "        \"\"\"\n",
        "        Construct a Dataset object to iterate over data X and labels y\n",
        "\n",
        "        Inputs:\n",
        "        - X: Numpy array of data, of any shape\n",
        "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
        "        - batch_size: Integer giving number of elements per minibatch\n",
        "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
        "        \"\"\"\n",
        "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
        "        self.X, self.y = X, y\n",
        "        self.batch_size, self.shuffle = batch_size, shuffle\n",
        "\n",
        "    def __iter__(self):\n",
        "        N, B = self.X.shape[0], self.batch_size\n",
        "        idxs = np.arange(N)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(idxs)\n",
        "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
        "\n",
        "\n",
        "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
        "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
        "test_dset = Dataset(X_test, y_test, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-21T10:32:03.438893Z",
          "start_time": "2024-03-21T10:32:03.392899Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxhBcG5Jmde0",
        "outputId": "ada0f915-0842-48ae-ebc0-ed17a52b26d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (64, 32, 32, 3) (64,)\n",
            "1 (64, 32, 32, 3) (64,)\n",
            "2 (64, 32, 32, 3) (64,)\n",
            "3 (64, 32, 32, 3) (64,)\n",
            "4 (64, 32, 32, 3) (64,)\n",
            "5 (64, 32, 32, 3) (64,)\n",
            "6 (64, 32, 32, 3) (64,)\n"
          ]
        }
      ],
      "source": [
        "# We can iterate through a dataset like this:\n",
        "for t, (x, y) in enumerate(train_dset):\n",
        "    print(t, x.shape, y.shape)\n",
        "    if t > 5: break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bBfBfYpmde1"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3Pofr7mmde1"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UqJbbQsmde1"
      },
      "source": [
        "#  Keras Model Subclassing API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMW3obRHmde1"
      },
      "source": [
        "\n",
        "Для реализации собственной модели с помощью Keras Model Subclassing API необходимо выполнить следующие шаги:\n",
        "\n",
        "1) Определить новый класс, который является наследником tf.keras.Model.\n",
        "\n",
        "2) В методе __init__() определить все необходимые слои из модуля tf.keras.layer\n",
        "\n",
        "3) Реализовать прямой проход в методе call() на основе слоев, объявленных в __init__()\n",
        "\n",
        "Ниже приведен пример использования keras API для определения двухслойной полносвязной сети.\n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-21T10:32:03.469890Z",
          "start_time": "2024-03-21T10:32:03.440894Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HXiyu_mmde1",
        "outputId": "f5d467d7-6c38-4a41-c8c3-23588653cc5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer VarianceScaling is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "class TwoLayerFC(tf.keras.Model):\n",
        "    def __init__(self, hidden_size, num_classes):\n",
        "        super(TwoLayerFC, self).__init__()\n",
        "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "        self.fc1 = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
        "                                   kernel_initializer=initializer)\n",
        "        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
        "                                   kernel_initializer=initializer)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def test_TwoLayerFC():\n",
        "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
        "    input_size, hidden_size, num_classes = 50, 42, 10\n",
        "    x = tf.zeros((64, input_size))\n",
        "    model = TwoLayerFC(hidden_size, num_classes)\n",
        "    # with tf.device(device):\n",
        "    scores = model(x)\n",
        "    print(scores.shape)\n",
        "\n",
        "test_TwoLayerFC()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v76VwT_cmde2"
      },
      "source": [
        "Реализуйте трехслойную CNN для вашей задачи классификации.\n",
        "\n",
        "Архитектура сети:\n",
        "    \n",
        "1. Сверточный слой (5 x 5 kernels, zero-padding = 'same')\n",
        "2. Функция активации ReLU\n",
        "3. Сверточный слой (3 x 3 kernels, zero-padding = 'same')\n",
        "4. Функция активации ReLU\n",
        "5. Полносвязный слой\n",
        "6. Функция активации Softmax\n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2D\n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-21T10:32:03.485889Z",
          "start_time": "2024-03-21T10:32:03.471890Z"
        },
        "id": "9V4lPunEmde2"
      },
      "outputs": [],
      "source": [
        "class ThreeLayerConvNet(tf.keras.Model):\n",
        "    def __init__(self, channel_1, channel_2, num_classes):\n",
        "        super(ThreeLayerConvNet, self).__init__()\n",
        "        ########################################################################\n",
        "        # Определение слоев для сверточной нейронной сети.\n",
        "        ########################################################################\n",
        "        self.conv1 = tf.keras.layers.Conv2D(channel_1, (5, 5), padding='same', activation='relu')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(channel_2, (3, 3), padding='same', activation='relu')\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        ########################################################################\n",
        "        # Прямой проход для сверточной нейронной сети.\n",
        "        ########################################################################\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-21T10:32:03.533896Z",
          "start_time": "2024-03-21T10:32:03.511895Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R34I4KXmde2",
        "outputId": "f5eaa650-713d-4b68-801b-7164814bfd19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10)\n"
          ]
        }
      ],
      "source": [
        "def test_ThreeLayerConvNet():\n",
        "    channel_1, channel_2, num_classes = 12, 8, 10\n",
        "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
        "    with tf.device(device):\n",
        "        x = tf.zeros((64, 3, 32, 32))\n",
        "        scores = model(x)\n",
        "        print(scores.shape)\n",
        "\n",
        "test_ThreeLayerConvNet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBh2BMKzmde2"
      },
      "source": [
        "Пример реализации процесса обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-21T10:32:03.581893Z",
          "start_time": "2024-03-21T10:32:03.562890Z"
        },
        "id": "OxOMn46Bmde3"
      },
      "outputs": [],
      "source": [
        "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False):\n",
        "    \"\"\"\n",
        "    Simple training loop for use with models defined using tf.keras. It trains\n",
        "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
        "    accuracy on the CIFAR-10 validation set.\n",
        "\n",
        "    Inputs:\n",
        "    - model_init_fn: A function that takes no parameters; when called it\n",
        "      constructs the model we want to train: model = model_init_fn()\n",
        "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
        "      constructs the Optimizer object we will use to optimize the model:\n",
        "      optimizer = optimizer_init_fn()\n",
        "    - num_epochs: The number of epochs to train for\n",
        "\n",
        "    Returns: Nothing, but prints progress during trainingn\n",
        "    \"\"\"\n",
        "    with tf.device(device):\n",
        "\n",
        "        # Compute the loss like we did in Part II\n",
        "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "        model = model_init_fn()\n",
        "        optimizer = optimizer_init_fn()\n",
        "\n",
        "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "        val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
        "\n",
        "        t = 0\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
        "            train_loss.reset_states()\n",
        "            train_accuracy.reset_states()\n",
        "\n",
        "            for x_np, y_np in train_dset:\n",
        "                with tf.GradientTape() as tape:\n",
        "\n",
        "                    # Use the model function to build the forward pass.\n",
        "                    scores = model(x_np, training=is_training)\n",
        "                    loss = loss_fn(y_np, scores)\n",
        "\n",
        "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "                    # Update the metrics\n",
        "                    train_loss.update_state(loss)\n",
        "                    train_accuracy.update_state(y_np, scores)\n",
        "\n",
        "                    if t % print_every == 0:\n",
        "                        val_loss.reset_states()\n",
        "                        val_accuracy.reset_states()\n",
        "                        for test_x, test_y in val_dset:\n",
        "                            # During validation at end of epoch, training set to False\n",
        "                            prediction = model(test_x, training=False)\n",
        "                            t_loss = loss_fn(test_y, prediction)\n",
        "\n",
        "                            val_loss.update_state(t_loss)\n",
        "                            val_accuracy.update_state(test_y, prediction)\n",
        "\n",
        "                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
        "                        print (template.format(t, epoch+1,\n",
        "                                             train_loss.result(),\n",
        "                                             train_accuracy.result()*100,\n",
        "                                             val_loss.result(),\n",
        "                                             val_accuracy.result()*100))\n",
        "                    t += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-21T10:32:34.721805Z",
          "start_time": "2024-03-21T10:32:03.751891Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKjdcmMhmde3",
        "outputId": "02d779ae-ad02-4d32-ff19-efd42d344c3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 3.1488828659057617, Accuracy: 10.9375, Val Loss: 2.684116840362549, Val Accuracy: 14.5\n",
            "Iteration 100, Epoch 1, Loss: 2.2259490489959717, Accuracy: 29.022275924682617, Val Loss: 1.872597098350525, Val Accuracy: 39.20000076293945\n",
            "Iteration 200, Epoch 1, Loss: 2.0744333267211914, Accuracy: 32.26057434082031, Val Loss: 1.8415042161941528, Val Accuracy: 39.29999923706055\n",
            "Iteration 300, Epoch 1, Loss: 2.003807544708252, Accuracy: 33.892234802246094, Val Loss: 1.8820589780807495, Val Accuracy: 37.29999923706055\n",
            "Iteration 400, Epoch 1, Loss: 1.9349920749664307, Accuracy: 35.750465393066406, Val Loss: 1.7254904508590698, Val Accuracy: 41.900001525878906\n",
            "Iteration 500, Epoch 1, Loss: 1.8890869617462158, Accuracy: 36.829463958740234, Val Loss: 1.6493014097213745, Val Accuracy: 44.60000228881836\n",
            "Iteration 600, Epoch 1, Loss: 1.860552430152893, Accuracy: 37.65599060058594, Val Loss: 1.6781830787658691, Val Accuracy: 43.0\n",
            "Iteration 700, Epoch 1, Loss: 1.8342262506484985, Accuracy: 38.369293212890625, Val Loss: 1.6218849420547485, Val Accuracy: 44.70000076293945\n"
          ]
        }
      ],
      "source": [
        "\n",
        "hidden_size, num_classes = 4000, 10\n",
        "learning_rate = 1e-2\n",
        "\n",
        "def model_init_fn():\n",
        "    return TwoLayerFC(hidden_size, num_classes)\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjGVqPb_mde3"
      },
      "source": [
        "Обучите трехслойную CNN. В tf.keras.optimizers.SGD укажите Nesterov momentum = 0.9 .\n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers/SGD\n",
        "\n",
        "Значение accuracy на валидационной выборке после 1 эпохи обучения должно быть > 50% ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-21T10:33:26.734189Z",
          "start_time": "2024-03-21T10:32:34.723805Z"
        },
        "id": "q-64ZL0mmde3",
        "outputId": "e1e7b50f-9e9c-4340-91da-d0ade64b3b8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 3065 calls to <function _BaseOptimizer._update_step_xla at 0x7a9af0d10670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 3066 calls to <function _BaseOptimizer._update_step_xla at 0x7a9af0d10670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 2.3979787826538086, Accuracy: 4.6875, Val Loss: 2.4270572662353516, Val Accuracy: 8.399999618530273\n",
            "Iteration 100, Epoch 1, Loss: 1.8665436506271362, Accuracy: 33.66336441040039, Val Loss: 1.6504309177398682, Val Accuracy: 43.29999923706055\n",
            "Iteration 200, Epoch 1, Loss: 1.7202601432800293, Accuracy: 39.1091423034668, Val Loss: 1.471838116645813, Val Accuracy: 49.70000076293945\n",
            "Iteration 300, Epoch 1, Loss: 1.6374460458755493, Accuracy: 41.60610580444336, Val Loss: 1.4420742988586426, Val Accuracy: 48.89999771118164\n",
            "Iteration 400, Epoch 1, Loss: 1.5725393295288086, Accuracy: 43.905860900878906, Val Loss: 1.3775074481964111, Val Accuracy: 50.70000457763672\n",
            "Iteration 500, Epoch 1, Loss: 1.5261958837509155, Accuracy: 45.44348907470703, Val Loss: 1.339013934135437, Val Accuracy: 51.70000076293945\n",
            "Iteration 600, Epoch 1, Loss: 1.496576189994812, Accuracy: 46.49282455444336, Val Loss: 1.2882561683654785, Val Accuracy: 55.19999694824219\n",
            "Iteration 700, Epoch 1, Loss: 1.4687752723693848, Accuracy: 47.53922653198242, Val Loss: 1.2920128107070923, Val Accuracy: 54.70000076293945\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 3e-3\n",
        "channel_1, channel_2, num_classes = 32, 16, 10\n",
        "\n",
        "def model_init_fn():\n",
        "    model = None\n",
        "    ############################################################################\n",
        "    # TODO: Complete the implementation of model_fn.                           #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                           END OF YOUR CODE                               #\n",
        "    ############################################################################\n",
        "    return model\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    optimizer = None\n",
        "    ############################################################################\n",
        "    # TODO: Complete the implementation of model_fn.                           #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                           END OF YOUR CODE                               #\n",
        "    ############################################################################\n",
        "    return optimizer\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPvuYgDWmde4"
      },
      "source": [
        "# Использование Keras Sequential API для реализации последовательных моделей.\n",
        "\n",
        "Пример для полносвязной сети:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-21T10:33:55.035281Z",
          "start_time": "2024-03-21T10:33:26.735190Z"
        },
        "id": "qjmdhDmSmde4",
        "outputId": "3e787cd1-d8c9-43be-ff8f-bd4378ff85e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 3.3933353424072266, Accuracy: 4.6875, Val Loss: 3.020481586456299, Val Accuracy: 13.0\n",
            "Iteration 100, Epoch 1, Loss: 2.225173234939575, Accuracy: 29.2852725982666, Val Loss: 1.9103121757507324, Val Accuracy: 37.099998474121094\n",
            "Iteration 200, Epoch 1, Loss: 2.07135009765625, Accuracy: 32.6881217956543, Val Loss: 1.820311188697815, Val Accuracy: 39.79999923706055\n",
            "Iteration 300, Epoch 1, Loss: 1.9982608556747437, Accuracy: 34.535919189453125, Val Loss: 1.864005208015442, Val Accuracy: 38.10000228881836\n",
            "Iteration 400, Epoch 1, Loss: 1.926121473312378, Accuracy: 36.36611557006836, Val Loss: 1.7324796915054321, Val Accuracy: 42.20000076293945\n",
            "Iteration 500, Epoch 1, Loss: 1.8825420141220093, Accuracy: 37.356536865234375, Val Loss: 1.6714897155761719, Val Accuracy: 43.5\n",
            "Iteration 600, Epoch 1, Loss: 1.8535958528518677, Accuracy: 38.18375778198242, Val Loss: 1.6830545663833618, Val Accuracy: 41.400001525878906\n",
            "Iteration 700, Epoch 1, Loss: 1.8286441564559937, Accuracy: 38.80393981933594, Val Loss: 1.6277868747711182, Val Accuracy: 43.70000076293945\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 1e-2\n",
        "\n",
        "def model_init_fn():\n",
        "    input_shape = (32, 32, 3)\n",
        "    hidden_layer_size, num_classes = 4000, 10\n",
        "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "    layers = [\n",
        "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
        "        tf.keras.layers.Dense(hidden_layer_size, activation='relu',\n",
        "                              kernel_initializer=initializer),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax',\n",
        "                              kernel_initializer=initializer),\n",
        "    ]\n",
        "    model = tf.keras.Sequential(layers)\n",
        "    return model\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvijUA_9mde4"
      },
      "source": [
        "Альтернативный менее гибкий способ обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-21T10:33:59.392586Z",
          "start_time": "2024-03-21T10:33:55.037282Z"
        },
        "id": "JJzOLRM2mde4",
        "outputId": "4f02a80c-b579-48ef-ff49-820d35067526",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "766/766 [==============================] - 4s 5ms/step - loss: 1.8182 - sparse_categorical_accuracy: 0.3914 - val_loss: 1.7531 - val_sparse_categorical_accuracy: 0.4210\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.7066 - sparse_categorical_accuracy: 0.4267\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7066301107406616, 0.42669999599456787]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model = model_init_fn()\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtXOP9immde4"
      },
      "source": [
        "Перепишите реализацию трехслойной CNN с помощью tf.keras.Sequential API . Обучите модель двумя способами."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-21T10:34:49.743065Z",
          "start_time": "2024-03-21T10:33:59.393586Z"
        },
        "id": "xv4nD7N3mde5",
        "outputId": "4e0ddd89-08b3-4abb-f062-d1a26ed46df1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 2.3882036209106445, Accuracy: 6.25, Val Loss: 2.31231427192688, Val Accuracy: 11.90000057220459\n",
            "Iteration 100, Epoch 1, Loss: 2.2553277015686035, Accuracy: 17.295793533325195, Val Loss: 2.2179737091064453, Val Accuracy: 19.100000381469727\n",
            "Iteration 200, Epoch 1, Loss: 2.221480369567871, Accuracy: 19.348569869995117, Val Loss: 2.155139923095703, Val Accuracy: 23.899999618530273\n",
            "Iteration 300, Epoch 1, Loss: 2.1951794624328613, Accuracy: 20.468231201171875, Val Loss: 2.1099038124084473, Val Accuracy: 25.700000762939453\n",
            "Iteration 400, Epoch 1, Loss: 2.164639472961426, Accuracy: 21.9217586517334, Val Loss: 2.065847635269165, Val Accuracy: 28.200000762939453\n",
            "Iteration 500, Epoch 1, Loss: 2.142360210418701, Accuracy: 22.879241943359375, Val Loss: 2.037090301513672, Val Accuracy: 28.200000762939453\n",
            "Iteration 600, Epoch 1, Loss: 2.1209280490875244, Accuracy: 23.765079498291016, Val Loss: 2.009662628173828, Val Accuracy: 29.80000114440918\n",
            "Iteration 700, Epoch 1, Loss: 2.1028754711151123, Accuracy: 24.47396469116211, Val Loss: 1.9843637943267822, Val Accuracy: 30.89999771118164\n"
          ]
        }
      ],
      "source": [
        "def model_init_fn():\n",
        "    model = None\n",
        "    ############################################################################\n",
        "    # TODO: Construct a three-layer ConvNet using tf.keras.Sequential.         #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                            END OF YOUR CODE                              #\n",
        "    ############################################################################\n",
        "    return model\n",
        "\n",
        "learning_rate = 5e-4\n",
        "def optimizer_init_fn():\n",
        "    optimizer = None\n",
        "    ############################################################################\n",
        "    # TODO: Complete the implementation of model_fn.                           #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                           END OF YOUR CODE                               #\n",
        "    ############################################################################\n",
        "    return optimizer\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "is_executing": true,
        "ExecuteTime": {
          "start_time": "2024-03-21T10:34:49.744065Z"
        },
        "id": "FIRJ96Exmde5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91652cea-40aa-4412-fd86-abdb37c41952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "766/766 [==============================] - 4s 5ms/step - loss: 1.6197 - sparse_categorical_accuracy: 0.4225 - val_loss: 1.3913 - val_sparse_categorical_accuracy: 0.5000\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.4156 - sparse_categorical_accuracy: 0.4935\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4155585765838623, 0.4934999942779541]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model = model_init_fn()\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMHQrrbzmde5"
      },
      "source": [
        "# Использование Keras Functional API\n",
        "\n",
        "Для реализации более сложных архитектур сети с несколькими входами/выходами, повторным использованием слоев, \"остаточными\" связями (residual connections) необходимо явно указать входные и выходные тензоры.\n",
        "\n",
        "Ниже представлен пример для полносвязной сети."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CdKAP4Gjmde5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ec5eb0-218e-42ae-e523-4b55dd22b0f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10)\n"
          ]
        }
      ],
      "source": [
        "def two_layer_fc_functional(input_shape, hidden_size, num_classes):\n",
        "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    flattened_inputs = tf.keras.layers.Flatten()(inputs)\n",
        "    fc1_output = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
        "                                 kernel_initializer=initializer)(flattened_inputs)\n",
        "    scores = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
        "                             kernel_initializer=initializer)(fc1_output)\n",
        "\n",
        "    # Instantiate the model given inputs and outputs.\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=scores)\n",
        "    return model\n",
        "\n",
        "def test_two_layer_fc_functional():\n",
        "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
        "    input_size, hidden_size, num_classes = 50, 42, 10\n",
        "    input_shape = (50,)\n",
        "\n",
        "    x = tf.zeros((64, input_size))\n",
        "    model = two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
        "\n",
        "    with tf.device(device):\n",
        "        scores = model(x)\n",
        "        print(scores.shape)\n",
        "\n",
        "test_two_layer_fc_functional()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wCnxBWsxmde5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a11af2-e38d-4ca3-9e32-0e837a891c07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 2.995513677597046, Accuracy: 15.625, Val Loss: 2.8921446800231934, Val Accuracy: 12.700000762939453\n",
            "Iteration 100, Epoch 1, Loss: 2.2282817363739014, Accuracy: 28.326114654541016, Val Loss: 1.9204689264297485, Val Accuracy: 36.89999771118164\n",
            "Iteration 200, Epoch 1, Loss: 2.068678140640259, Accuracy: 32.1750602722168, Val Loss: 1.8840391635894775, Val Accuracy: 37.0\n",
            "Iteration 300, Epoch 1, Loss: 1.9973726272583008, Accuracy: 34.26079559326172, Val Loss: 1.8862063884735107, Val Accuracy: 36.599998474121094\n",
            "Iteration 400, Epoch 1, Loss: 1.926774501800537, Accuracy: 36.2258415222168, Val Loss: 1.746034026145935, Val Accuracy: 40.400001525878906\n",
            "Iteration 500, Epoch 1, Loss: 1.8849895000457764, Accuracy: 37.20683670043945, Val Loss: 1.6628777980804443, Val Accuracy: 42.39999771118164\n",
            "Iteration 600, Epoch 1, Loss: 1.8547316789627075, Accuracy: 38.06936264038086, Val Loss: 1.6916673183441162, Val Accuracy: 41.5\n",
            "Iteration 700, Epoch 1, Loss: 1.8302843570709229, Accuracy: 38.6768913269043, Val Loss: 1.66720449924469, Val Accuracy: 42.29999923706055\n"
          ]
        }
      ],
      "source": [
        "input_shape = (32, 32, 3)\n",
        "hidden_size, num_classes = 4000, 10\n",
        "learning_rate = 1e-2\n",
        "\n",
        "def model_init_fn():\n",
        "    return two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejJunY24mde6"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9Gcduahmde6"
      },
      "source": [
        "Поэкспериментируйте с архитектурой сверточной сети. Для вашего набора данных вам необходимо получить как минимум 70% accuracy на валидационной выборке за 10 эпох обучения. Опишите все эксперименты и сделайте выводы (без выполнения данного пункта работы приниматься не будут).\n",
        "\n",
        "Эспериментируйте с архитектурой, гиперпараметрами, функцией потерь, регуляризацией, методом оптимизации.  \n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/BatchNormalization#methods https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dropout#methods"
      ]
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "class _IdentityBlock(tf.keras.Model):\n",
        "    \"\"\"Identity block utilizing skip connections.\"\"\"\n",
        "\n",
        "    def __init__(self, out_channels):\n",
        "        super().__init__()\n",
        "        \"\"\"Initializes the identiy block.\n",
        "\n",
        "        Here we simply initialize 2 layers which process the input and after the output\n",
        "        is produces it is added together with the input whcih is the final output.\n",
        "\n",
        "        Args:\n",
        "            out_channels (int): The number of activation maps this block should produce\n",
        "        \"\"\"\n",
        "        # Acts as Kaiming weight initalization\n",
        "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "\n",
        "        # Part 1 of the convolution, normalization and non-linearity\n",
        "        self.conv1 = tf.keras.layers.Conv2D(out_channels, 3, padding='same', use_bias=False, kernel_initializer=initializer)\n",
        "        self.norm1 = tf.keras.layers.BatchNormalization(axis=3)\n",
        "        self.relu1 = tf.keras.layers.Activation('relu')\n",
        "\n",
        "        # Part 2 of the convolution, normalization and non-linearity\n",
        "        self.conv2 = tf.keras.layers.Conv2D(out_channels, 3, padding='same', use_bias=False, kernel_initializer=initializer)\n",
        "        self.norm2 = tf.keras.layers.BatchNormalization(axis=3)\n",
        "        self.relu2 = tf.keras.layers.Activation('relu')\n",
        "\n",
        "        # Add layer will add together the input and the output\n",
        "        self.add = tf.keras.layers.Add()\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        \"\"\"Performs forward pass on the given input.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor):      The input of dimensions (N, H, W, C)\n",
        "            training (bool): Indicates whether the forward pass happens in the training mode\n",
        "\n",
        "        Returns:\n",
        "              out (Tensor): Output data of dim (N, H, W, C)\n",
        "        \"\"\"\n",
        "        x_skip = tf.identity(x)                   # prepare to add the input to the output\n",
        "        x = self.relu1(self.norm1(self.conv1(x))) # pass input through the first layer\n",
        "        x = self.norm2(self.conv2(x))             # pass input through the second layer (without ReLU)\n",
        "        out = self.relu2(self.add([x, x_skip]))   # perform ReLU on the processed input added with the raw input\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, in_channels=32, block_config=(2, 2, 2, 2), num_classes=10):\n",
        "        \"\"\"Initializes the residual network.\n",
        "\n",
        "        The first layer produces `in_channels` activation maps which are then fed to a\n",
        "        sequence of blocks containing a specified number of identity sub-blocks (first\n",
        "        block is always *_BottleneckBlock*). At the end the _global average pooling_\n",
        "        layer is used to flatten the activations for the linear softmax classifier.\n",
        "\n",
        "        Args:\n",
        "            in_channels (int):    The number of channels to extract after the first convolution\n",
        "            block_config (tuple): The number of layers each bloack should have in sequence\n",
        "            num_classes (int):    The total number of classes\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Acts as Kaiming weight initalization\n",
        "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "\n",
        "        # Prepare the input for the chains of identity blocks\n",
        "        self.features = tf.keras.Sequential([\n",
        "            tf.keras.layers.Conv2D(in_channels, 5, padding='same', use_bias=False, kernel_initializer=initializer),\n",
        "            tf.keras.layers.BatchNormalization(axis=3),\n",
        "            tf.keras.layers.Activation('relu'),\n",
        "        ])\n",
        "\n",
        "        num_features = in_channels # num feaure maps to produce after each group of identity blocks\n",
        "\n",
        "        # Loop through every group of blocks\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            # Use bottleneck block as the first block in every group (except first)\n",
        "            if i != 0:\n",
        "                self.features.add(_BottleneckBlock(num_features))\n",
        "            else:\n",
        "                self.features.add(_IdentityBlock(num_features))\n",
        "\n",
        "            # Create the specified number of identity blocks for i'th group\n",
        "            for j in range(num_layers-1):\n",
        "                self.features.add(_IdentityBlock(num_features))\n",
        "\n",
        "            num_features *= 2 # increase the nuber of features to be produced\n",
        "\n",
        "        # Flatten the final activation maps using global average pooling\n",
        "        self.features.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "\n",
        "        # Softmax classifier is used as the final layer\n",
        "        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax', kernel_initializer=initializer)\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        \"\"\"Performs forward pass on the given input.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor):      The input of dimensions (N, H, W, C)\n",
        "            training (bool): Indicates whether the forward pass happens in the training mode\n",
        "\n",
        "        Returns:\n",
        "            out (Tensor): Output data of dim (N, 10)\n",
        "        \"\"\"\n",
        "        out = self.features(x)     # Get the extracted features for the linear classfier\n",
        "        out = self.classifier(out) # Perform classification with softmax activation\n",
        "\n",
        "        return out\n",
        "class _BottleneckBlock(tf.keras.Model):\n",
        "    \"\"\"Same as identity block except it reduces the spacial area before processing the input.\"\"\"\n",
        "\n",
        "    def __init__(self, out_channels):\n",
        "        \"\"\"Initializes the bottleneck block.\n",
        "\n",
        "        Unlike *_IdentityBlock*, the first convolution here reduces the spacial size of the input\n",
        "        by a factor of `2`. Then, it performs the main convolution after which the output maps\n",
        "        are added together with the input maps to produce final activations.\n",
        "\n",
        "        Args:\n",
        "            out_channels (int): The number of activation maps this block should produce\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Acts as Kaiming weight initalization\n",
        "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "\n",
        "        # Reduce the input size by 2 to match output size\n",
        "        self.skip1 = tf.keras.layers.Conv2D(out_channels, 2, strides=2, use_bias=False, kernel_initializer=initializer)\n",
        "\n",
        "        # Part 1 of the convolution which reduces the spacial area\n",
        "        self.conv1 = tf.keras.layers.Conv2D(out_channels, 3, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)\n",
        "        self.norm1 = tf.keras.layers.BatchNormalization(axis=3)\n",
        "        self.relu1 = tf.keras.layers.Activation('relu')\n",
        "\n",
        "        # Part 2 of the convolution which extracts features from the reduced input\n",
        "        self.conv2 = tf.keras.layers.Conv2D(out_channels, 3, padding='same', use_bias=False, kernel_initializer=initializer)\n",
        "        self.norm2 = tf.keras.layers.BatchNormalization(axis=3)\n",
        "        self.relu2 = tf.keras.layers.Activation('relu')\n",
        "\n",
        "        # Add layer will add together the input and the output\n",
        "        self.add = tf.keras.layers.Add()\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        \"\"\"Performs forward pass on the given input.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor):      The input of dimensions (N, H, W, C)\n",
        "            training (bool): Indicates whether the forward pass happens in the training mode\n",
        "\n",
        "        Returns:\n",
        "            out (Tensor): Output data of dim (N, H/2, W/2, out_channels)\n",
        "        \"\"\"\n",
        "        x_skip = self.skip1(x)                    # prepare to add the input to the output\n",
        "        x = self.relu1(self.norm1(self.conv1(x))) # pass input through the first layer\n",
        "        x = self.norm2(self.conv2(x))             # pass input through the second layer (without ReLU)\n",
        "        out = self.relu2(self.add([x, x_skip]))   # perform ReLU on the processed input added with the raw input\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "dyKT825Imde6"
      },
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "W4l_Ityxmde6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1749d277-95cf-4ad9-b8ca-7a7b95e4a9f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 5.723515033721924, Accuracy: 14.0625, Val Loss: 96.11455535888672, Val Accuracy: 8.90000057220459\n",
            "Iteration 100, Epoch 1, Loss: 1.9524948596954346, Accuracy: 33.555076599121094, Val Loss: 3.626565933227539, Val Accuracy: 17.700000762939453\n",
            "Iteration 200, Epoch 1, Loss: 1.72105872631073, Accuracy: 39.47450256347656, Val Loss: 2.184948444366455, Val Accuracy: 38.0\n",
            "Iteration 300, Epoch 1, Loss: 1.5955733060836792, Accuracy: 43.293190002441406, Val Loss: 1.7420998811721802, Val Accuracy: 47.20000076293945\n",
            "Iteration 400, Epoch 1, Loss: 1.5009397268295288, Accuracy: 46.47755432128906, Val Loss: 1.2915042638778687, Val Accuracy: 54.29999923706055\n",
            "Iteration 500, Epoch 1, Loss: 1.432699203491211, Accuracy: 48.7618522644043, Val Loss: 1.270981788635254, Val Accuracy: 53.89999771118164\n",
            "Iteration 600, Epoch 1, Loss: 1.3808494806289673, Accuracy: 50.668155670166016, Val Loss: 1.2471815347671509, Val Accuracy: 56.0\n",
            "Iteration 700, Epoch 1, Loss: 1.3317935466766357, Accuracy: 52.38052749633789, Val Loss: 1.1176414489746094, Val Accuracy: 60.39999771118164\n",
            "Iteration 800, Epoch 2, Loss: 0.9643334746360779, Accuracy: 66.33928680419922, Val Loss: 1.1192646026611328, Val Accuracy: 62.599998474121094\n",
            "Iteration 900, Epoch 2, Loss: 0.9437582492828369, Accuracy: 66.5740737915039, Val Loss: 0.9749741554260254, Val Accuracy: 65.9000015258789\n",
            "Iteration 1000, Epoch 2, Loss: 0.9301806688308716, Accuracy: 67.09441375732422, Val Loss: 1.2327572107315063, Val Accuracy: 62.400001525878906\n",
            "Iteration 1100, Epoch 2, Loss: 0.9081050157546997, Accuracy: 67.90111541748047, Val Loss: 0.9754554033279419, Val Accuracy: 68.0\n",
            "Iteration 1200, Epoch 2, Loss: 0.888612687587738, Accuracy: 68.55603790283203, Val Loss: 1.1225967407226562, Val Accuracy: 62.0\n",
            "Iteration 1300, Epoch 2, Loss: 0.8706637024879456, Accuracy: 69.13843536376953, Val Loss: 0.9244362711906433, Val Accuracy: 67.0\n",
            "Iteration 1400, Epoch 2, Loss: 0.855815052986145, Accuracy: 69.67765808105469, Val Loss: 1.0450325012207031, Val Accuracy: 63.599998474121094\n",
            "Iteration 1500, Epoch 2, Loss: 0.8372659683227539, Accuracy: 70.2869873046875, Val Loss: 0.9915710687637329, Val Accuracy: 66.79999542236328\n",
            "Iteration 1600, Epoch 3, Loss: 0.6693804860115051, Accuracy: 76.87953186035156, Val Loss: 0.7445906400680542, Val Accuracy: 74.5999984741211\n",
            "Iteration 1700, Epoch 3, Loss: 0.6774733662605286, Accuracy: 76.08172607421875, Val Loss: 0.9257822036743164, Val Accuracy: 69.19999694824219\n",
            "Iteration 1800, Epoch 3, Loss: 0.6700620651245117, Accuracy: 76.19075012207031, Val Loss: 1.8638545274734497, Val Accuracy: 51.20000076293945\n",
            "Iteration 1900, Epoch 3, Loss: 0.6629536747932434, Accuracy: 76.48627471923828, Val Loss: 1.0913180112838745, Val Accuracy: 66.0\n",
            "Iteration 2000, Epoch 3, Loss: 0.6454333662986755, Accuracy: 77.02891540527344, Val Loss: 0.770781934261322, Val Accuracy: 73.69999694824219\n",
            "Iteration 2100, Epoch 3, Loss: 0.6350124478340149, Accuracy: 77.3890609741211, Val Loss: 1.118919014930725, Val Accuracy: 63.70000076293945\n",
            "Iteration 2200, Epoch 3, Loss: 0.623012125492096, Accuracy: 77.89844512939453, Val Loss: 0.9194607734680176, Val Accuracy: 70.20000457763672\n",
            "Iteration 2300, Epoch 4, Loss: 0.4955770671367645, Accuracy: 82.29167175292969, Val Loss: 1.2518258094787598, Val Accuracy: 64.0999984741211\n",
            "Iteration 2400, Epoch 4, Loss: 0.49613311886787415, Accuracy: 82.73665618896484, Val Loss: 1.0970920324325562, Val Accuracy: 69.5\n",
            "Iteration 2500, Epoch 4, Loss: 0.49636396765708923, Accuracy: 82.62007141113281, Val Loss: 1.2037445306777954, Val Accuracy: 68.0999984741211\n",
            "Iteration 2600, Epoch 4, Loss: 0.4887666702270508, Accuracy: 83.0909652709961, Val Loss: 0.9943631291389465, Val Accuracy: 67.4000015258789\n",
            "Iteration 2700, Epoch 4, Loss: 0.4867500066757202, Accuracy: 83.072265625, Val Loss: 1.3197461366653442, Val Accuracy: 62.0\n",
            "Iteration 2800, Epoch 4, Loss: 0.47404345870018005, Accuracy: 83.48657989501953, Val Loss: 0.9430885910987854, Val Accuracy: 72.89999389648438\n",
            "Iteration 2900, Epoch 4, Loss: 0.4685382544994354, Accuracy: 83.64169311523438, Val Loss: 1.079673409461975, Val Accuracy: 66.19999694824219\n",
            "Iteration 3000, Epoch 4, Loss: 0.45636671781539917, Accuracy: 84.08161163330078, Val Loss: 1.0122618675231934, Val Accuracy: 69.4000015258789\n",
            "Iteration 3100, Epoch 5, Loss: 0.37233802676200867, Accuracy: 87.3310775756836, Val Loss: 1.443037748336792, Val Accuracy: 60.60000228881836\n",
            "Iteration 3200, Epoch 5, Loss: 0.3671819865703583, Accuracy: 87.00958251953125, Val Loss: 1.0341960191726685, Val Accuracy: 70.5\n",
            "Iteration 3300, Epoch 5, Loss: 0.36269932985305786, Accuracy: 87.21650695800781, Val Loss: 0.8518650531768799, Val Accuracy: 75.0999984741211\n",
            "Iteration 3400, Epoch 5, Loss: 0.3553449511528015, Accuracy: 87.63445281982422, Val Loss: 0.9068603515625, Val Accuracy: 73.5999984741211\n",
            "Iteration 3500, Epoch 5, Loss: 0.350579172372818, Accuracy: 87.88257598876953, Val Loss: 1.2432148456573486, Val Accuracy: 68.80000305175781\n",
            "Iteration 3600, Epoch 5, Loss: 0.3426705300807953, Accuracy: 88.16922760009766, Val Loss: 1.098555326461792, Val Accuracy: 67.79999542236328\n",
            "Iteration 3700, Epoch 5, Loss: 0.33495500683784485, Accuracy: 88.39776611328125, Val Loss: 1.025224208831787, Val Accuracy: 70.9000015258789\n",
            "Iteration 3800, Epoch 5, Loss: 0.328342080116272, Accuracy: 88.60456085205078, Val Loss: 1.2234159708023071, Val Accuracy: 69.5999984741211\n",
            "Iteration 3900, Epoch 6, Loss: 0.253631591796875, Accuracy: 91.30722045898438, Val Loss: 1.044297695159912, Val Accuracy: 73.29999542236328\n",
            "Iteration 4000, Epoch 6, Loss: 0.2692915201187134, Accuracy: 90.61585998535156, Val Loss: 0.9939948320388794, Val Accuracy: 73.69999694824219\n",
            "Iteration 4100, Epoch 6, Loss: 0.26958876848220825, Accuracy: 90.53275299072266, Val Loss: 1.2988905906677246, Val Accuracy: 69.4000015258789\n",
            "Iteration 4200, Epoch 6, Loss: 0.2656615674495697, Accuracy: 90.74713897705078, Val Loss: 1.257493257522583, Val Accuracy: 67.79999542236328\n",
            "Iteration 4300, Epoch 6, Loss: 0.25712859630584717, Accuracy: 91.03636169433594, Val Loss: 1.081882357597351, Val Accuracy: 72.69999694824219\n",
            "Iteration 4400, Epoch 6, Loss: 0.25254884362220764, Accuracy: 91.16133880615234, Val Loss: 1.3577854633331299, Val Accuracy: 68.5\n",
            "Iteration 4500, Epoch 6, Loss: 0.24926640093326569, Accuracy: 91.30262756347656, Val Loss: 1.3466354608535767, Val Accuracy: 68.69999694824219\n",
            "Iteration 4600, Epoch 7, Loss: 0.17055466771125793, Accuracy: 92.1875, Val Loss: 1.3948582410812378, Val Accuracy: 70.5999984741211\n",
            "Iteration 4700, Epoch 7, Loss: 0.19002124667167664, Accuracy: 92.75297546386719, Val Loss: 1.2203446626663208, Val Accuracy: 70.5999984741211\n",
            "Iteration 4800, Epoch 7, Loss: 0.1940007507801056, Accuracy: 92.66767883300781, Val Loss: 1.0233585834503174, Val Accuracy: 75.4000015258789\n",
            "Iteration 4900, Epoch 7, Loss: 0.19914840161800385, Accuracy: 92.69979858398438, Val Loss: 1.202226996421814, Val Accuracy: 73.79999542236328\n",
            "Iteration 5000, Epoch 7, Loss: 0.19556443393230438, Accuracy: 92.90123748779297, Val Loss: 1.2142846584320068, Val Accuracy: 70.0\n",
            "Iteration 5100, Epoch 7, Loss: 0.19002583622932434, Accuracy: 93.1621322631836, Val Loss: 1.265306830406189, Val Accuracy: 71.5999984741211\n",
            "Iteration 5200, Epoch 7, Loss: 0.1907511055469513, Accuracy: 93.20247650146484, Val Loss: 1.1688742637634277, Val Accuracy: 70.9000015258789\n",
            "Iteration 5300, Epoch 7, Loss: 0.1879308670759201, Accuracy: 93.29122161865234, Val Loss: 0.868780791759491, Val Accuracy: 76.0999984741211\n",
            "Iteration 5400, Epoch 8, Loss: 0.14376717805862427, Accuracy: 94.95191955566406, Val Loss: 1.0527355670928955, Val Accuracy: 75.70000457763672\n",
            "Iteration 5500, Epoch 8, Loss: 0.14500313997268677, Accuracy: 94.95278930664062, Val Loss: 1.2202916145324707, Val Accuracy: 74.4000015258789\n",
            "Iteration 5600, Epoch 8, Loss: 0.1447741836309433, Accuracy: 94.83525085449219, Val Loss: 1.0531237125396729, Val Accuracy: 73.0\n",
            "Iteration 5700, Epoch 8, Loss: 0.14961832761764526, Accuracy: 94.73635864257812, Val Loss: 1.1260558366775513, Val Accuracy: 73.69999694824219\n",
            "Iteration 5800, Epoch 8, Loss: 0.14690203964710236, Accuracy: 94.82132720947266, Val Loss: 1.2189277410507202, Val Accuracy: 72.0\n",
            "Iteration 5900, Epoch 8, Loss: 0.1437303125858307, Accuracy: 94.91825103759766, Val Loss: 1.2740124464035034, Val Accuracy: 70.5999984741211\n",
            "Iteration 6000, Epoch 8, Loss: 0.14192673563957214, Accuracy: 95.02396392822266, Val Loss: 1.2090799808502197, Val Accuracy: 71.4000015258789\n",
            "Iteration 6100, Epoch 8, Loss: 0.1404501050710678, Accuracy: 95.09049987792969, Val Loss: 1.2017773389816284, Val Accuracy: 73.19999694824219\n",
            "Iteration 6200, Epoch 9, Loss: 0.11414486169815063, Accuracy: 95.97602844238281, Val Loss: 1.28578782081604, Val Accuracy: 73.19999694824219\n",
            "Iteration 6300, Epoch 9, Loss: 0.11553823947906494, Accuracy: 95.80021667480469, Val Loss: 0.9762019515037537, Val Accuracy: 76.80000305175781\n",
            "Iteration 6400, Epoch 9, Loss: 0.11821949481964111, Accuracy: 95.83905792236328, Val Loss: 1.7336970567703247, Val Accuracy: 68.30000305175781\n",
            "Iteration 6500, Epoch 9, Loss: 0.12176015973091125, Accuracy: 95.64762115478516, Val Loss: 1.2216053009033203, Val Accuracy: 73.4000015258789\n",
            "Iteration 6600, Epoch 9, Loss: 0.12064856290817261, Accuracy: 95.70560455322266, Val Loss: 1.454852819442749, Val Accuracy: 71.5\n",
            "Iteration 6700, Epoch 9, Loss: 0.11871743947267532, Accuracy: 95.80060577392578, Val Loss: 1.0111238956451416, Val Accuracy: 75.5999984741211\n",
            "Iteration 6800, Epoch 9, Loss: 0.11815990507602692, Accuracy: 95.84185028076172, Val Loss: 1.091902732849121, Val Accuracy: 76.4000015258789\n",
            "Iteration 6900, Epoch 10, Loss: 0.09254399687051773, Accuracy: 96.875, Val Loss: 1.1328085660934448, Val Accuracy: 75.0\n",
            "Iteration 7000, Epoch 10, Loss: 0.10409188270568848, Accuracy: 96.29088592529297, Val Loss: 1.2382022142410278, Val Accuracy: 73.5\n",
            "Iteration 7100, Epoch 10, Loss: 0.10966772586107254, Accuracy: 96.09752655029297, Val Loss: 1.2206534147262573, Val Accuracy: 73.0999984741211\n",
            "Iteration 7200, Epoch 10, Loss: 0.1104990690946579, Accuracy: 96.05558013916016, Val Loss: 1.0970408916473389, Val Accuracy: 77.10000610351562\n",
            "Iteration 7300, Epoch 10, Loss: 0.10735706239938736, Accuracy: 96.21468353271484, Val Loss: 1.0237756967544556, Val Accuracy: 77.60000610351562\n",
            "Iteration 7400, Epoch 10, Loss: 0.10363218933343887, Accuracy: 96.32643127441406, Val Loss: 1.3371573686599731, Val Accuracy: 73.4000015258789\n",
            "Iteration 7500, Epoch 10, Loss: 0.10323960334062576, Accuracy: 96.31126403808594, Val Loss: 1.2904008626937866, Val Accuracy: 73.9000015258789\n",
            "Iteration 7600, Epoch 10, Loss: 0.10311492532491684, Accuracy: 96.3224868774414, Val Loss: 1.2133712768554688, Val Accuracy: 76.80000305175781\n"
          ]
        }
      ],
      "source": [
        "class CustomConvNet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CustomConvNet, self).__init__()\n",
        "        ############################################################################\n",
        "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
        "        ############################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        self.model = ResNet()\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ############################################################################\n",
        "        #                            END OF YOUR CODE                              #\n",
        "        ############################################################################\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        ############################################################################\n",
        "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
        "        ############################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        x = self.model.call(input_tensor, training)\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ############################################################################\n",
        "        #                            END OF YOUR CODE                              #\n",
        "        ############################################################################\n",
        "        return x\n",
        "\n",
        "\n",
        "print_every = 100\n",
        "num_epochs = 10\n",
        "\n",
        "model = CustomConvNet()\n",
        "\n",
        "def model_init_fn():\n",
        "    return CustomConvNet()\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    learning_rate = 1e-3\n",
        "    return tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nREnkxK3mde7"
      },
      "source": [
        "Опишите все эксперименты, результаты. Сделайте выводы."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kWa5BMuIroCi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y5OZJJumde7"
      },
      "outputs": [],
      "source": [
        "  Была реализована следующая архитектура:\n",
        "        1. `CONV->NORM->RELU->CONV->NORM->RELU` для предварительной обработки входного сигнала для цепочки блоков слоев\n",
        "        2. `IDENTITY->[BOTTLENECK->IDENTITY] x N`, где каждый блок состоит из произвольного\n",
        "           где каждый блок состоит из произвольного количества слоев, использующих \"skip\" соединения\n",
        "        3. `POOL->DENSE->SOFTMAX`, где выполняется глобальное усреднение пула\n",
        "           перед вычислением raw scores\n",
        "В результате произведенной работы были получены необходимые результаты уже на 3 эпохе"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}